{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced_programming_11_SuperCase_2_Structured_data_v7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DrxrDO6nYSD"
      },
      "source": [
        "## Confidentiality\r\n",
        "\r\n",
        "The programmatic cases in this notebook are utilized from different internet resources (in this notebook especially from kaggle.com) and are for demonstrational purposes only.\r\n",
        "\r\n",
        "Please do not copy or distribute this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PQoND12sACj"
      },
      "source": [
        "## Table of content\r\n",
        "\r\n",
        "Census Income Data\r\n",
        "\r\n",
        "1. Programmatic case 1 \r\n",
        "2. Programmatic case 2\r\n",
        "3. Programmatic case 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLUIUwPnsELp"
      },
      "source": [
        "## Previous knowledge\r\n",
        "\r\n",
        "For a good understanding of this notebook you should have a few years of data-science and programming experience and have studied the advanced programming notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1_j49VDnBw-"
      },
      "source": [
        "## Introduction\r\n",
        "\r\n",
        "A supercase is a case for a dataset on which multiple data-science methods and techniques can be applied.\r\n",
        "There is no predifined goal. The goal is to explore cases for the dataset with multiple data-science methods, techniques and programs.\r\n",
        "The goal is to built more specific cases with specific goals. A supercase contains information to built multiple new specific cases. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccMRinl6sIcd"
      },
      "source": [
        "#### Programmatic case 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xomz_Y5RsPiX"
      },
      "source": [
        "######################################################################################################################\r\n",
        "######################################################################################################################\r\n",
        "##1) Prediction 1 - Advanced Program \r\n",
        "\r\n",
        "#1.1) Keras regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7Q3FI19qLF9"
      },
      "source": [
        "# Use seaborn for pairplot\r\n",
        "!pip install -q seaborn\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "# Make numpy printouts easier to read.\r\n",
        "np.set_printoptions(precision=3, suppress=True)\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "print(tf.__version__)\r\n",
        "\r\n",
        "\r\n",
        "test_path = '/content/census_data.csv'\r\n",
        "\r\n",
        "raw_dataset = pd.read_csv(test_path)\r\n",
        "\r\n",
        "dataset = raw_dataset.copy()\r\n",
        "dataset.tail()\r\n",
        "\r\n",
        "dataset.isna().sum()\r\n",
        "\r\n",
        "dataset = dataset.dropna()\r\n",
        "\r\n",
        "dataset['education-num'] = dataset['education-num'].map({1: 'level_1', 2: 'level_2', 3: 'level_3'})\r\n",
        "\r\n",
        "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\r\n",
        "dataset.tail()\r\n",
        "\r\n",
        "train_dataset = dataset.sample(frac=0.8, random_state=0)\r\n",
        "test_dataset = dataset.drop(train_dataset.index)\r\n",
        "\r\n",
        "sns.pairplot(train_dataset[['income_level_num', 'hours-per-week', 'capital-gain', 'capital-loss']], diag_kind='kde')\r\n",
        "\r\n",
        "train_dataset.describe().transpose()\r\n",
        "\r\n",
        "train_features = train_dataset.copy()\r\n",
        "test_features = test_dataset.copy()\r\n",
        "\r\n",
        "train_labels = train_features.pop('income_level_num')\r\n",
        "test_labels = test_features.pop('income_level_num')\r\n",
        "\r\n",
        "train_dataset.describe().transpose()[['mean', 'std']]\r\n",
        "\r\n",
        "normalizer = preprocessing.Normalization()\r\n",
        "\r\n",
        "normalizer.adapt(np.array(train_features))\r\n",
        "\r\n",
        "print(normalizer.mean.numpy())\r\n",
        "\r\n",
        "first = np.array(train_features[:1])\r\n",
        "\r\n",
        "with np.printoptions(precision=2, suppress=True):\r\n",
        "  print('First example:', first)\r\n",
        "  print()\r\n",
        "  print('Normalized:', normalizer(first).numpy())\r\n",
        "  \r\n",
        "  \r\n",
        "Age = np.array(train_features['Age'])\r\n",
        "\r\n",
        "Age_normalizer = preprocessing.Normalization(input_shape=[1,])\r\n",
        "Age_normalizer.adapt(Age)\r\n",
        "\r\n",
        "\r\n",
        "Age_model = tf.keras.Sequential([\r\n",
        "    Age_normalizer,\r\n",
        "    layers.Dense(units=1)\r\n",
        "])\r\n",
        "\r\n",
        "Age_model.summary()\r\n",
        "\r\n",
        "Age_model.predict(Age[:10])\r\n",
        "\r\n",
        "Age_model.compile(\r\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\r\n",
        "    loss='mean_absolute_error')\r\n",
        "\t\r\n",
        "\t\r\n",
        "history = Age_model.fit(\r\n",
        "    train_features['Age'], train_labels,\r\n",
        "    epochs=100,\r\n",
        "    # suppress logging\r\n",
        "    verbose=0,\r\n",
        "    # Calculate validation results on 20% of the training data\r\n",
        "    validation_split = 0.2)\r\n",
        "\t\r\n",
        "\t\r\n",
        "hist = pd.DataFrame(history.history)\r\n",
        "hist['epoch'] = history.epoch\r\n",
        "hist.tail()\r\n",
        "\r\n",
        "\r\n",
        "def plot_loss(history):\r\n",
        "  plt.plot(history.history['loss'], label='loss')\r\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\r\n",
        "  plt.ylim([0, 10])\r\n",
        "  plt.xlabel('Epoch')\r\n",
        "  plt.ylabel('Error [income_level_num]')\r\n",
        "  plt.legend()\r\n",
        "  plt.grid(True)\r\n",
        "  \r\n",
        "  \r\n",
        "plot_loss(history)\r\n",
        "\r\n",
        "test_results = {}\r\n",
        "\r\n",
        "test_results['Age_model'] = Age_model.evaluate(\r\n",
        "    test_features['Age'],\r\n",
        "    test_labels, verbose=0)\r\n",
        "\t\r\n",
        "x = tf.linspace(0.0, 250, 251)\r\n",
        "y = Age_model.predict(x)\r\n",
        "\r\n",
        "\r\n",
        "def plot_Age(x, y):\r\n",
        "  plt.scatter(train_features['Age'], train_labels, label='Data')\r\n",
        "  plt.plot(x, y, color='k', label='Predictions')\r\n",
        "  plt.xlabel('Age')\r\n",
        "  plt.ylabel('income_level_num')\r\n",
        "  plt.legend()\r\n",
        "  \r\n",
        "plot_Age(x,y)\r\n",
        "\r\n",
        "\r\n",
        "linear_model = tf.keras.Sequential([\r\n",
        "    normalizer,\r\n",
        "    layers.Dense(units=1)\r\n",
        "])\r\n",
        "\r\n",
        "linear_model.predict(train_features[:10])\r\n",
        "\r\n",
        "linear_model.layers[1].kernel\r\n",
        "\r\n",
        "linear_model.compile(\r\n",
        "    optimizer=tf.optimizers.Adam(learning_rate=0.1),\r\n",
        "    loss='mean_absolute_error')\r\n",
        "\t\r\n",
        "\t\r\n",
        "history = linear_model.fit(\r\n",
        "    train_features, train_labels, \r\n",
        "    epochs=100,\r\n",
        "    # suppress logging\r\n",
        "    verbose=0,\r\n",
        "    # Calculate validation results on 20% of the training data\r\n",
        "    validation_split = 0.2)\r\n",
        "\t\r\n",
        "\t\r\n",
        "plot_loss(history)\r\n",
        "\r\n",
        "test_results['linear_model'] = linear_model.evaluate(\r\n",
        "    test_features, test_labels, verbose=0)\r\n",
        "\t\r\n",
        "def build_and_compile_model(norm):\r\n",
        "  model = keras.Sequential([\r\n",
        "      norm,\r\n",
        "      layers.Dense(64, activation='relu'),\r\n",
        "      layers.Dense(64, activation='relu'),\r\n",
        "      layers.Dense(1)\r\n",
        "  ])\r\n",
        "\r\n",
        "  model.compile(loss='mean_absolute_error',\r\n",
        "                optimizer=tf.keras.optimizers.Adam(0.001))\r\n",
        "  return model\r\n",
        "  \r\n",
        "dnn_Age_model = build_and_compile_model(Age_normalizer)\r\n",
        "\r\n",
        "dnn_Age_model.summary()\r\n",
        "\r\n",
        "history = dnn_Age_model.fit(\r\n",
        "    train_features['Age'], train_labels,\r\n",
        "    validation_split=0.2,\r\n",
        "    verbose=0, epochs=100)\r\n",
        "\t\r\n",
        "plot_loss(history)\r\n",
        "\r\n",
        "x = tf.linspace(0.0, 250, 251)\r\n",
        "y = dnn_Age_model.predict(x)\r\n",
        "\r\n",
        "plot_Age(x, y)\r\n",
        "\r\n",
        "test_results['dnn_Age_model'] = dnn_Age_model.evaluate(\r\n",
        "    test_features['Age'], test_labels,\r\n",
        "    verbose=0)\r\n",
        "\t\r\n",
        "dnn_model = build_and_compile_model(normalizer)\r\n",
        "dnn_model.summary()\r\n",
        "\r\n",
        "history = dnn_model.fit(\r\n",
        "    train_features, train_labels,\r\n",
        "    validation_split=0.2,\r\n",
        "    verbose=0, epochs=100)\r\n",
        "\t\r\n",
        "plot_loss(history)\r\n",
        "\r\n",
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=0)\r\n",
        "\r\n",
        "pd.DataFrame(test_results, index=['Mean absolute error [income_level_num]']).T\r\n",
        "\r\n",
        "test_predictions = dnn_model.predict(test_features).flatten()\r\n",
        "\r\n",
        "a = plt.axes(aspect='equal')\r\n",
        "plt.scatter(test_labels, test_predictions)\r\n",
        "plt.xlabel('True Values [income_level_num]')\r\n",
        "plt.ylabel('Predictions [income_level_num]')\r\n",
        "lims = [0, 50]\r\n",
        "plt.xlim(lims)\r\n",
        "plt.ylim(lims)\r\n",
        "_ = plt.plot(lims, lims)\r\n",
        "\r\n",
        "\r\n",
        "error = test_predictions - test_labels\r\n",
        "plt.hist(error, bins=25)\r\n",
        "plt.xlabel('Prediction Error [income_level_num]')\r\n",
        "_ = plt.ylabel('Count')\r\n",
        "\r\n",
        "\r\n",
        "dnn_model.save('dnn_model')\r\n",
        "\r\n",
        "reloaded = tf.keras.models.load_model('dnn_model')\r\n",
        "\r\n",
        "test_results['reloaded'] = reloaded.evaluate(\r\n",
        "    test_features, test_labels, verbose=0)\r\n",
        "\t\r\n",
        "pd.DataFrame(test_results, index=['Mean absolute error [income_level_num]']).T\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXPv3PtcynXj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx_ZwNt6yngG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruDB0o7CuPIY"
      },
      "source": [
        "#### Programmatic case 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85tzKaGaqKgP"
      },
      "source": [
        "######################################################################################################################\r\n",
        "######################################################################################################################\r\n",
        "##2) Prediction 2 - Advanced Program \r\n",
        "\r\n",
        "#2.1) DNN Classifier "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpb9bzF-3X7C"
      },
      "source": [
        "\r\n",
        "import tensorflow as tf\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "path = '/content/census_data.csv'\r\n",
        "\r\n",
        "train = pd.read_csv(path)\r\n",
        "\r\n",
        "train\r\n",
        "\r\n",
        "CSV_COLUMN_NAMES = ['Age', 'education-num', 'hours-per-week', 'income_level_cat']\r\n",
        "INCOME_LEVEL = ['<50K', '>50K']\r\n",
        "\r\n",
        "train = train[[\"Age\", \"education-num\", \"hours-per-week\", \"income_level_cat\"]]\r\n",
        "\r\n",
        "train.head()\r\n",
        "\r\n",
        "train.dtypes\r\n",
        "\r\n",
        "train[\"income_level_cat2\"] = train[\"income_level_cat\"].astype('category')\r\n",
        "train.dtypes\r\n",
        "\r\n",
        "train[\"income_level_cat2\"] = train[\"income_level_cat2\"].cat.codes\r\n",
        "train.head()\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "# split into train test sets\r\n",
        "X = train\r\n",
        "X_train, X_test= train_test_split(X, train_size=0.70)\r\n",
        "print(X_train.shape, X_test.shape)\r\n",
        "\r\n",
        "# split features and dependent\r\n",
        "train_y = X_train[\"income_level_cat2\"]\r\n",
        "train = X_train.drop(\"income_level_cat2\", axis=1)\r\n",
        "test_y = X_test[\"income_level_cat2\"]\r\n",
        "test = X_test.drop(\"income_level_cat2\", axis=1)\r\n",
        "\r\n",
        "train = X_train.drop([\"income_level_cat\",\"income_level_cat2\"], axis=1)\r\n",
        "test = X_test.drop([\"income_level_cat\",\"income_level_cat2\"], axis=1)\r\n",
        "\r\n",
        "train.head()\r\n",
        "\r\n",
        "train_y = train_y.astype(np.int32)\r\n",
        "test_y = test_y.astype(np.int32)\r\n",
        "\r\n",
        "train.head()\r\n",
        "\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "def input_evaluation_set():\r\n",
        "    features = {'Age': np.array([39, 38]),\r\n",
        "                'education-num':  np.array([13, 9]),\r\n",
        "                'hours-per-week': np.array([40, 40])}\r\n",
        "    labels = np.array([0, 0], dtype=np.int32)\r\n",
        "    return features, labels\r\n",
        "\t\r\n",
        "\r\n",
        "def input_fn(features, labels, training=True, batch_size=256):\r\n",
        "    \"\"\"An input function for training or evaluating\"\"\"\r\n",
        "    # Converting the inputs to a Dataset.\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n",
        "\r\n",
        "    # Shuffling and repeat if you are in training mode.\r\n",
        "    if training:\r\n",
        "        dataset = dataset.shuffle(1000).repeat()\r\n",
        "    \r\n",
        "    return dataset.batch(batch_size)\r\n",
        "\t\r\n",
        "# Feature columns describe how to use the input.\r\n",
        "my_feature_columns = []\r\n",
        "for key in train.keys():\r\n",
        "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n",
        "\t\r\n",
        "# Building a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\r\n",
        "classifier = tf.estimator.DNNClassifier(\r\n",
        "    feature_columns=my_feature_columns,\r\n",
        "    # Two hidden layers of 30 and 10 nodes respectively.\r\n",
        "    hidden_units=[30, 10],\r\n",
        "    # The model must choose between 3 classes.\r\n",
        "    n_classes=2)\r\n",
        "\t\r\n",
        "train.head()\r\n",
        "\r\n",
        "# Training the Model.\r\n",
        "classifier.train(\r\n",
        "    input_fn=lambda: input_fn(train, train_y, training=True),\r\n",
        "    steps=5000)\r\n",
        "\t\r\n",
        "eval_result = classifier.evaluate(\r\n",
        "    input_fn=lambda: input_fn(test, test_y, training=False))\r\n",
        "\r\n",
        "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\r\n",
        "\r\n",
        "# Generating predictions from the model\r\n",
        "expected = ['<50K', '>50K']\r\n",
        "predict_x = {\r\n",
        "    'Age': [5.1, 5.9],\r\n",
        "    'education-num': [3.3, 3.0],\r\n",
        "    'hours-per-week': [1.7, 4.2],\r\n",
        "}\r\n",
        "\r\n",
        "def input_fn(features, batch_size=256):\r\n",
        "    \"\"\"An input function for prediction.\"\"\"\r\n",
        "    # Converting the inputs to a Dataset without labels.\r\n",
        "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\r\n",
        "\r\n",
        "predictions = classifier.predict(\r\n",
        "    input_fn=lambda: input_fn(predict_x))\r\n",
        "\t\r\n",
        "for pred_dict, expec in zip(predictions, expected):\r\n",
        "    class_id = pred_dict['class_ids'][0]\r\n",
        "    probability = pred_dict['probabilities'][class_id]\r\n",
        "\r\n",
        "    print('Prediction is \"{}\" ({:.1f}%), expected \"{}\"'.format(\r\n",
        "        INCOME_LEVEL[class_id], 100 * probability, expec))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnOCj4yn3YAj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmcTdRG23YIL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnCEmz7LqTgh"
      },
      "source": [
        "#### Programmatic case 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns0-b4TEF6Cm"
      },
      "source": [
        "######################################################################################################################\r\n",
        "######################################################################################################################\r\n",
        "##1) Prediction 3 - Advanced Program \r\n",
        "\r\n",
        "#3.1) Tensorflow linear models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMdRigkg5eqv"
      },
      "source": [
        "\r\n",
        "!pip install -q sklearn\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import json, math, os, sys\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from IPython.display import clear_output\r\n",
        "from six.moves import urllib\r\n",
        "\r\n",
        "import tensorflow.compat.v2.feature_column as fc\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "path = '/content/census_data.csv'\r\n",
        "\r\n",
        "train = pd.read_csv(path)\r\n",
        "\r\n",
        "train[\"income_level_cat2\"] = train[\"income_level_cat\"].astype('category')\r\n",
        "train.dtypes\r\n",
        "\r\n",
        "train[\"income_level_cat2\"] = train[\"income_level_cat2\"].cat.codes\r\n",
        "train.head()\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "# split into train test sets\r\n",
        "X = train\r\n",
        "X_train, X_test= train_test_split(X, train_size=0.70)\r\n",
        "print(X_train.shape, X_test.shape)\r\n",
        "\r\n",
        "# split features and dependent\r\n",
        "y_train = X_train[\"income_level_cat2\"]\r\n",
        "dftrain = X_train.drop(\"income_level_cat2\", axis=1)\r\n",
        "y_eval = X_test[\"income_level_cat2\"]\r\n",
        "dfeval = X_test.drop(\"income_level_cat2\", axis=1)\r\n",
        "\r\n",
        "dftrain.head()\r\n",
        "\r\n",
        "dftrain.describe()\r\n",
        "\r\n",
        "dftrain.shape[0], dfeval.shape[0]\r\n",
        "\r\n",
        "dftrain.Age.hist(bins=20)\r\n",
        "\r\n",
        "dftrain.Gender.value_counts().plot(kind='barh')\r\n",
        "\r\n",
        "dftrain['workclass'].value_counts().plot(kind='barh')\r\n",
        "\r\n",
        "pd.concat([dftrain, y_train], axis=1).groupby('Gender').income_level_cat2.mean().plot(kind='barh').set_xlabel('% income_level_cat2')\r\n",
        "\r\n",
        "\r\n",
        "CATEGORICAL_COLUMNS = [\"workclass\", \"education\", \"marital-status\", \"occupation\",\r\n",
        "                       \"relationship\", \"Clothing\", \"Gender\", \"native-country\"]\r\n",
        "NUMERIC_COLUMNS = [\"Age\", \"education-num\", \"capital-gain\", \"capital-loss\",\r\n",
        "                      \"hours-per-week\"]\r\n",
        "\r\n",
        "feature_columns = []\r\n",
        "for feature_name in CATEGORICAL_COLUMNS:\r\n",
        "  vocabulary = dftrain[feature_name].unique()\r\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\r\n",
        "\r\n",
        "for feature_name in NUMERIC_COLUMNS:\r\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\r\n",
        "  \r\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\r\n",
        "  def input_function():\r\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\r\n",
        "    if shuffle:\r\n",
        "      ds = ds.shuffle(1000)\r\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)\r\n",
        "    return ds\r\n",
        "  return input_function\r\n",
        "\r\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\r\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\r\n",
        "\r\n",
        "ds = make_input_fn(dftrain, y_train, batch_size=10)()\r\n",
        "for feature_batch, label_batch in ds.take(1):\r\n",
        "  print('Some feature keys:', list(feature_batch.keys()))\r\n",
        "  print()\r\n",
        "  print('A batch of class:', feature_batch['workclass'].numpy())\r\n",
        "  print()\r\n",
        "  print('A batch of Labels:', label_batch.numpy())\r\n",
        "  \r\n",
        "age_column = feature_columns[8]\r\n",
        "tf.keras.layers.DenseFeatures([age_column])(feature_batch).numpy()\r\n",
        "\r\n",
        "gender_column = feature_columns[6]\r\n",
        "tf.keras.layers.DenseFeatures([tf.feature_column.indicator_column(gender_column)])(feature_batch).numpy()\r\n",
        "\r\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\r\n",
        "linear_est.train(train_input_fn)\r\n",
        "result = linear_est.evaluate(eval_input_fn)\r\n",
        "\r\n",
        "clear_output()\r\n",
        "print(result)\r\n",
        "\r\n",
        "age_x_gender = tf.feature_column.crossed_column(['Age', 'Gender'], hash_bucket_size=100)\r\n",
        "\r\n",
        "derived_feature_columns = [age_x_gender]\r\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns+derived_feature_columns)\r\n",
        "linear_est.train(train_input_fn)\r\n",
        "result = linear_est.evaluate(eval_input_fn)\r\n",
        "\r\n",
        "clear_output()\r\n",
        "print(result)\r\n",
        "\r\n",
        "pred_dicts = list(linear_est.predict(eval_input_fn))\r\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\r\n",
        "\r\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities')\r\n",
        "\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "fpr, tpr, _ = roc_curve(y_eval, probs)\r\n",
        "plt.plot(fpr, tpr)\r\n",
        "plt.title('ROC curve')\r\n",
        "plt.xlabel('false positive rate')\r\n",
        "plt.ylabel('true positive rate')\r\n",
        "plt.xlim(0,)\r\n",
        "plt.ylim(0,)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}