{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Santander custumer satisfaction_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCXh3gJtYSEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Table of content\n",
        "\n",
        "#1 Prediction 1\n",
        "#1.1 Fast GBM\n",
        "#1.2 Load libraries\n",
        "#1.3 Reading in data \n",
        "#1.4 Data pre-processing\n",
        "#1.5 Split train/test\n",
        "#1.6 Fast GBM 1\n",
        "#1.7 Fast GBM 2 \n",
        "#1.8 Fast GBM 3\n",
        "#1.9 Prediction\n",
        "\n",
        "#2 Prediction 2 \n",
        "#2.1 Auto modelling\n",
        "#2.2 Imputation\n",
        "#2.3 Hyper-parameter tuning\n",
        "#2.4 Optimized predictive model GBM \n",
        "#2.5 Prediction\n",
        "\n",
        "#3 Prediction 3\n",
        "#3.1 GBM with all variables \n",
        "#3.2 Fast GBM 4 \n",
        "#3.3 Prediction\n",
        "\n",
        "#4 Prediction 4\n",
        "#4.1 Ensembling\n",
        "#4.2 Stacking ensemble\n",
        "\n",
        "#5 Prediction 5\n",
        "#5.1 EDA in-depth analysis\n",
        "#5.2 Descriptive statistics\n",
        "#5.3 The Y/response variable\n",
        "#5.4 Correlation\n",
        "#5.5 PCA full dataframe\n",
        "#5.6 PCA reduced dataframe\n",
        "#5.7 PCA PC's automatically selected\n",
        "\n",
        "#6 Prediction 6\n",
        "#6.1 Lean XG Boost\n",
        "#6.2 Prediction\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lEJCjzGi6fO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1) Prediction 1  \n",
        "\n",
        "#1.1) Fast GBM \n",
        "\n",
        "#First we will apply a fast GBM for quick first results and valuable insight in the data."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKkNXVufkKNR",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.2) Load libraries\n",
        "\n",
        "# data analysis and wrangling\n",
        "import numpy as np\n",
        "import random as rnd\n",
        "import pandas as pd\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from collections import Counter\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import mean_squared_error,roc_auc_score,precision_score\n",
        "\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_classification\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve \n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import learning_curve,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import random\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKm-yXIJkfZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.3) Reading in data \n",
        "\n",
        "# Reading in data\n",
        "uploaded = files.upload()\n",
        "# Storing data in a Pandas dataframe\n",
        "train = pd.read_csv(io.BytesIO(uploaded['train.csv']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP4YdVuRknIm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.4) Data pre-processing\n",
        "\n",
        "train = pd.DataFrame(train)\n",
        "print(\"Original DataFrame:\")\n",
        "print(train)\n",
        "train = train.sample(frac=1)\n",
        "print(\"\\nNew DataFrame:\")\n",
        "print(train)\n",
        "\n",
        "#Subset data\n",
        "train.iloc[0:20000]\n",
        "\n",
        "train.dtypes\n",
        "\n",
        "train['TARGET'].dtypes\n",
        "\n",
        "myvars = train[[\"TARGET\",\"var3\",\"var15\",\"var38\"]]\n",
        "train1 = myvars\n",
        "\n",
        "myvars\n",
        "\n",
        "train.isnull().sum().sum()\n",
        "train.isnull().sum()\n",
        "\n",
        "sns.catplot(x=\"TARGET\", kind=\"count\", data=train1)\n",
        "\n",
        "## Fast feature importance (Feature importance = probably the most valuable result you can get, \n",
        "# So you want to get it as fast as possible)\n",
        "X = train\n",
        "Y_train = X[\"TARGET\"]\n",
        "X_train = X.drop(\"TARGET\", axis=1)\n",
        "\n",
        "model = LGBMClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,18))\n",
        "lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
        "ax.grid(False)\n",
        "plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "## Fast feature importance (advanced)\n",
        "\n",
        "## # Split dataset and dependent\n",
        "## Y_train = train[\"TARGET\"]\n",
        "## X_train = train.drop(\"TARGET\", axis=1)\n",
        "## OR\n",
        "## Y_train = train[\"TARGET\"]\n",
        "## X_train = train\n",
        "## #scaling the features using Standard Scaler\n",
        "## sc=StandardScaler()\n",
        "## sc.fit(X_train)\n",
        "## X=pd.DataFrame(sc.fit_transform(X_train))\n",
        "## #train_test_split \n",
        "## X_train,X_test,y_train,y_test=train_test_split(X,Y_train,test_size=0.3,random_state=0)\n",
        "## #converting the dataset into proper LGB format \n",
        "## d_train=lgb.Dataset(X_train, label=y_train)\n",
        "## #Specifying the parameter\n",
        "## params={}\n",
        "## params['learning_rate']=0.03\n",
        "## params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
        "## params['objective']='binary' #Binary target feature\n",
        "## params['metric']='binary_logloss' #metric for binary classification\n",
        "## params['max_depth']=10\n",
        "## #train the model \n",
        "## model=lgb.train(params,d_train,100) #train the model on 100 epocs\n",
        "## #prediction on the test set\n",
        "## # Feature importance\n",
        "## y_pred=model.predict(X_test)\n",
        "## fig, ax = plt.subplots(figsize=(12,18))\n",
        "## lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
        "## ax.grid(False)\n",
        "## plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
        "## plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkqI79gJ4qM_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.5) Split train/test\n",
        "\n",
        "# split into train test sets\n",
        "X = train\n",
        "X_train, X_test= train_test_split(X, train_size=0.70)\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "# split features and dependent\n",
        "Y_train = X_train[\"TARGET\"]\n",
        "X_train = X_train.drop(\"TARGET\", axis=1)\n",
        "Y_test = X_test[\"TARGET\"]\n",
        "X_test = X_test.drop(\"TARGET\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1MQRAfrgxTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.6) Fast GBM 1\n",
        "\n",
        "# GBM classifier 1\n",
        "model = GradientBoostingClassifier(\n",
        "        learning_rate=0.1, \n",
        "        n_estimators=100,\n",
        "        max_depth=3, \n",
        "        min_samples_split=2, \n",
        "        min_samples_leaf=1, \n",
        "        subsample=1,\n",
        "        max_features='sqrt', \n",
        "        random_state=10)\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_train = accuracy_score(pred_train,Y_train)\n",
        "accuracy_test = accuracy_score(pred_test,Y_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train), model.predict_proba(X_train)[:,1])\n",
        "auc_train = metrics.auc(fpr,tpr)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test), model.predict_proba(X_test)[:,1])\n",
        "auc_test = metrics.auc(fpr,tpr)\n",
        "\n",
        "## Cross validation accuracy\n",
        "cross_val_rfc = cross_val_score(estimator=GradientBoostingClassifier(), X=X_train, y=Y_train, cv=2, n_jobs=-1)\n",
        "\n",
        "# R Cross validation accuracy\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# evaluate the model on the dataset\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#Print model report:\n",
        "print(\"\\nModel Report\")\n",
        "print('AUC:',(auc_test))\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "print(\"Cross Validation Accuracy: \")\n",
        "print(classification_report(Y_test, pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t0fZZPwXSg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.6) Fast GBM 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj2k2lmmXSlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exclude the ID column\n",
        "X = train.drop(\"ID\", axis=1)\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test= train_test_split(X, train_size=0.70)\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "# Split features/dependent\n",
        "Y_train = X_train[\"TARGET\"]\n",
        "X_train = X_train.drop(\"TARGET\", axis=1)\n",
        "Y_test = X_test[\"TARGET\"]\n",
        "X_test = X_test.drop(\"TARGET\", axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPTzFeifl8o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GBM classifier 2\n",
        "model = GradientBoostingClassifier(\n",
        "        learning_rate=0.1, \n",
        "        n_estimators=100,\n",
        "        max_depth=3, \n",
        "        min_samples_split=2, \n",
        "        min_samples_leaf=1, \n",
        "        subsample=1,\n",
        "        max_features='sqrt', \n",
        "        random_state=10)\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_train = accuracy_score(pred_train,Y_train)\n",
        "accuracy_test = accuracy_score(pred_test,Y_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train), model.predict_proba(X_train)[:,1])\n",
        "auc_train = metrics.auc(fpr,tpr)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test), model.predict_proba(X_test)[:,1])\n",
        "auc_test = metrics.auc(fpr,tpr)\n",
        "\n",
        "## Cross validation accuracy\n",
        "cross_val_rfc = cross_val_score(estimator=GradientBoostingClassifier(), X=X_train, y=Y_train, cv=2, n_jobs=-1)\n",
        "\n",
        "# R Cross validation accuracy\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# evaluate the model on the dataset\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#Print model report:\n",
        "print(\"\\nModel Report\")\n",
        "print('AUC:',(auc_test))\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "print(\"Cross Validation Accuracy: \")\n",
        "print(classification_report(Y_test, pred_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2jDZ04xW2jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##1.8) Fast GBM 3 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO805eOJW2yH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating clean dataset\n",
        "myvars = train[[\"TARGET\",\"var3\",\"var15\",\"var38\"]]\n",
        "train1 = myvars\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test= train_test_split(train1, train_size=0.70)\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "# Split features/dependent\n",
        "Y_train = X_train[\"TARGET\"]\n",
        "X_train = X_train.drop(\"TARGET\", axis=1)\n",
        "Y_test = X_test[\"TARGET\"]\n",
        "X_test = X_test.drop(\"TARGET\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agq8kNkHW2fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GBM classifier 3\n",
        "model = GradientBoostingClassifier(\n",
        "        learning_rate=0.1, \n",
        "        n_estimators=100,\n",
        "        max_depth=3, \n",
        "        min_samples_split=2, \n",
        "        min_samples_leaf=1, \n",
        "        subsample=1,\n",
        "        max_features='sqrt', \n",
        "        random_state=10)\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_train = accuracy_score(pred_train,Y_train)\n",
        "accuracy_test = accuracy_score(pred_test,Y_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train), model.predict_proba(X_train)[:,1])\n",
        "auc_train = metrics.auc(fpr,tpr)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test), model.predict_proba(X_test)[:,1])\n",
        "auc_test = metrics.auc(fpr,tpr)\n",
        "\n",
        "## Cross validation accuracy\n",
        "cross_val_rfc = cross_val_score(estimator=GradientBoostingClassifier(), X=X_train, y=Y_train, cv=2, n_jobs=-1)\n",
        "\n",
        "# R Cross validation accuracy\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# evaluate the model on the dataset\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#Print model report:\n",
        "print(\"\\nModel Report\")\n",
        "print('AUC:',(auc_test))\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "print(\"Cross Validation Accuracy: \")\n",
        "print(classification_report(Y_test, pred_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glaFD-6KoBKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 1.9 Prediction\n",
        "\n",
        "## ROC/AUC \n",
        "\n",
        "print(\"Roc : \",(fpr, tpr, _))\n",
        "print(\"Auc : \",(auc_test))\n",
        "\n",
        "## Confusion matrix\n",
        "print(\"Confusion matrix : \", confusion_matrix(Y_test, pred_test))\n",
        "\n",
        "## Crosstab\n",
        "pd.crosstab(Y_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "\n",
        "## cross validation accuracy\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "\n",
        "## R cross validation accuracy\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# ROC AUC plot\n",
        "#baseline model\n",
        "baseline_roc_auc = roc_auc_score(Y_test, model.predict(X_test))\n",
        "fprB, tprB, thresholdsB = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
        "## #model 1\n",
        "## model1_roc_auc = roc_auc_score(y_test, model1.predict(X_test))\n",
        "## fpr1, tpr1, thresholds1 = roc_curve(y_test, model1.predict_proba(X_test)[:,1])\n",
        "## #new tuned model \n",
        "## new_roc_auc = roc_auc_score(y_test, new.predict(X_test))\n",
        "## fprnew, tprnew, thresholds_new = roc_curve(y_test, new.predict_proba(X_test)[:,1])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fprB, tprB, label='GBM Baseline (area = %0.2f)' % baseline_roc_auc)\n",
        "## plt.plot(fpr1, tpr1, label='GBM Model 1 (area = %0.2f)' % model1_roc_auc)\n",
        "## plt.plot(fprnew, tprnew, label='GBM Final Model (area = %0.2f)' % new_roc_auc)\n",
        "\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUyCbi3aRx3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##2) Prediction 2 \n",
        "                            \n",
        "#2.1) Auto-modelling \n",
        "                            \n",
        "#First we'll apply a fast GBM for quick first results and valuable insight in the data.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyFvUudgCvih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##2.2 Imputation\n",
        "\n",
        "train2.head(3)\n",
        "\n",
        "#Checking for Na's in dataframe\n",
        "train2.isnull().any()#Will return the feature with True or False,True means have missing value else False\n",
        "\n",
        "## Split train/test\n",
        "# create dataset\n",
        "X = train2\n",
        "# split into train test sets\n",
        "X_train, X_test= train_test_split(X, train_size=0.70)\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "# Prepare dataset\n",
        "X_train['Type']='Train' #Create a flag for Train and Test Data set\n",
        "X_test['Type']='Test'\n",
        "fullData = pd.concat([X_train,X_test],axis=0) #Combined both Train and Test Data set\n",
        "\n",
        "ID_col = ['PassengerId']\n",
        "target_col = [\"Survived\"]\n",
        "cat_cols = ['Name','Sex','Ticket','Cabin','Embarked']\n",
        "num_cols= list(set(list(fullData.columns))-set(cat_cols)-set(ID_col)-set(target_col))\n",
        "other_col=['Type'] #Test and Train Data set identifier\n",
        "\n",
        "num_cat_cols = num_cols+cat_cols # Combined numerical and Categorical variables\n",
        "\n",
        "#Create a new variable for each variable having missing value with VariableName_NA \n",
        "# and flag missing value with 1 and other with 0\n",
        "\n",
        "for var in num_cat_cols:\n",
        "     if fullData[var].isnull().any()==True:\n",
        "        fullData[var+'_NA']=fullData[var].isnull()*1 \n",
        "\n",
        "#Impute numerical missing values with mean\n",
        "fullData[num_cols] = fullData[num_cols].fillna(fullData[num_cols].mean(),inplace=True)\n",
        "\n",
        "#Impute categorical missing values with -9999\n",
        "fullData[cat_cols] = fullData[cat_cols].fillna(value = -9999)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzTG0DT8bBTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 2.3 Encoding numeric features \n",
        "\n",
        "for var in cat_cols:\n",
        " number = LabelEncoder()\n",
        " fullData[var] = number.fit_transform(fullData[var].astype('str'))\n",
        "\n",
        "#Target variable is also a categorical so convert it\n",
        "fullData[\"Survived\"] = number.fit_transform(fullData[\"Survived\"].astype('str'))\n",
        "\n",
        "train=fullData[fullData['Type']=='Train']\n",
        "test=fullData[fullData['Type']=='Test']\n",
        "\n",
        "train['is_train'] = np.random.uniform(0, 1, len(train)) <= .75\n",
        "Train, Validate = train[train['is_train']==True], train[train['is_train']==False]\n",
        "\n",
        "features=list(set(list(fullData.columns))-set(ID_col)-set(target_col)-set(other_col))\n",
        "\n",
        "x_train = Train[list(features)].values\n",
        "y_train = Train[\"Survived\"].values\n",
        "x_validate = Validate[list(features)].values\n",
        "y_validate = Validate[\"Survived\"].values\n",
        "x_test=test[list(features)].values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAt6hs4z8Bec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 2.4 Hyperparameter tuning \n",
        "\n",
        "# define the grid of values to search\n",
        "grid = dict()\n",
        "grid['n_estimators'] = [10, 50, 100, 500] \n",
        "grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
        "grid['subsample'] = [0.5, 0.7, 1.0]\n",
        "grid['max_depth'] = [3, 7, 9]\n",
        "# define the evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# define the grid search procedure\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy')\n",
        "# execute the grid search\n",
        "grid_result = grid_search.fit(X_train, Y_train)\n",
        "# summarize the best score and configuration\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "# summarize all scores that were evaluated\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCZPrgm-Xe1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "#2.5) Optimized predictive model GBM \n",
        "\n",
        "# GBM classifier \n",
        "model = GradientBoostingClassifier(\n",
        "        learning_rate=0.1, \n",
        "        n_estimators=100,\n",
        "        max_depth=3, \n",
        "        min_samples_split=2, \n",
        "        min_samples_leaf=1, \n",
        "        subsample=1,\n",
        "        max_features='sqrt', \n",
        "        random_state=10)\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_train = accuracy_score(pred_train,Y_train)\n",
        "accuracy_test = accuracy_score(pred_test,Y_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train), model.predict_proba(X_train)[:,1])\n",
        "auc_train = metrics.auc(fpr,tpr)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test), model.predict_proba(X_test)[:,1])\n",
        "auc_test = metrics.auc(fpr,tpr)\n",
        "\n",
        "## Cross validation accuracy\n",
        "cross_val_rfc = cross_val_score(estimator=GradientBoostingClassifier(), X=X_train, y=Y_train, cv=2, n_jobs=-1)\n",
        "\n",
        "# R Cross validation accuracy\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# evaluate the model on the dataset\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#Print model report:\n",
        "print(\"\\nModel Report\")\n",
        "print('AUC:',(auc_test))\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "print(\"Cross Validation Accuracy: \")\n",
        "print(classification_report(Y_test, pred_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHjVkM-3-97g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "##2.6) Prediction  \n",
        "\n",
        "## Predictions\n",
        "\n",
        "## ROC/AUC \n",
        "\n",
        "print(\"Roc : \",(fpr, tpr, _))\n",
        "print(\"Auc : \",(auc_test))\n",
        "\n",
        "## Confusion matrix\n",
        "print(\"Confusion matrix : \", confusion_matrix(Y_test, pred_test))\n",
        "\n",
        "## Crosstab\n",
        "pd.crosstab(Y_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "\n",
        "## cross validation accuracy\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "\n",
        "## R cross validation accuracy\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# ROC AUC plot\n",
        "#baseline model\n",
        "baseline_roc_auc = roc_auc_score(Y_test, model.predict(X_test))\n",
        "fprB, tprB, thresholdsB = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
        "## #model 1\n",
        "## model1_roc_auc = roc_auc_score(y_test, model1.predict(X_test))\n",
        "## fpr1, tpr1, thresholds1 = roc_curve(y_test, model1.predict_proba(X_test)[:,1])\n",
        "## #new tuned model \n",
        "## new_roc_auc = roc_auc_score(y_test, new.predict(X_test))\n",
        "## fprnew, tprnew, thresholds_new = roc_curve(y_test, new.predict_proba(X_test)[:,1])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fprB, tprB, label='GBM Baseline (area = %0.2f)' % baseline_roc_auc)\n",
        "## plt.plot(fpr1, tpr1, label='GBM Model 1 (area = %0.2f)' % model1_roc_auc)\n",
        "## plt.plot(fprnew, tprnew, label='GBM Final Model (area = %0.2f)' % new_roc_auc)\n",
        "\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaz9DtbOegsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##3) Prediction 3 \n",
        "\n",
        "#3.1) GBM with all effecting variables. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "519Vt8CLek4l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##3.2 Fast GBM 4\n",
        "\n",
        "# Effecting variables >20\n",
        "model = LGBMClassifier()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,18))\n",
        "lgb.plot_importance(model, max_num_features=50, height=0.8, ax=ax)\n",
        "ax.grid(False)\n",
        "plt.title(\"LightGBM - Feature Importance\", fontsize=15)\n",
        "plt.show()\n",
        "\n",
        "#Creating clean dataset\n",
        "myvars = train[[\"TARGET\",\"var3\",\"saldo_medio_var5_hace3\",\"saldo_medio_var5_hace2\"]]\n",
        "train1 = myvars\n",
        "\n",
        "# Split train/test\n",
        "X_train, X_test= train_test_split(train1, train_size=0.70)\n",
        "print(X_train.shape, X_test.shape)\n",
        "\n",
        "# Split features/dependent\n",
        "Y_train = X_train[\"TARGET\"]\n",
        "X_train = X_train.drop(\"TARGET\", axis=1)\n",
        "Y_test = X_test[\"TARGET\"]\n",
        "X_test = X_test.drop(\"TARGET\", axis=1)\n",
        "\n",
        "\n",
        "# GBM classifier 1\n",
        "model = GradientBoostingClassifier(\n",
        "        learning_rate=0.1, \n",
        "        n_estimators=100,\n",
        "        max_depth=3, \n",
        "        min_samples_split=2, \n",
        "        min_samples_leaf=1, \n",
        "        subsample=1,\n",
        "        max_features='sqrt', \n",
        "        random_state=10)\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_train = accuracy_score(pred_train,Y_train)\n",
        "accuracy_test = accuracy_score(pred_test,Y_test)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_train), model.predict_proba(X_train)[:,1])\n",
        "auc_train = metrics.auc(fpr,tpr)\n",
        "\n",
        "fpr, tpr, _ = metrics.roc_curve(np.array(Y_test), model.predict_proba(X_test)[:,1])\n",
        "auc_test = metrics.auc(fpr,tpr)\n",
        "\n",
        "## Cross validation accuracy\n",
        "cross_val_rfc = cross_val_score(estimator=GradientBoostingClassifier(), X=X_train, y=Y_train, cv=2, n_jobs=-1)\n",
        "\n",
        "# R Cross validation accuracy\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# evaluate the model on the dataset\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
        "\n",
        "#Print model report:\n",
        "print(\"\\nModel Report\")\n",
        "print('AUC:',(auc_test))\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "print(\"Cross Validation Accuracy: \")\n",
        "print(classification_report(Y_test, pred_test))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LzZCFPz6e9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "##3.3 Prediction\n",
        "\n",
        "## Predictions\n",
        "\n",
        "## ROC/AUC \n",
        "\n",
        "print(\"Roc : \",(fpr, tpr, _))\n",
        "print(\"Auc : \",(auc_test))\n",
        "\n",
        "## Confusion matrix\n",
        "print(\"Confusion matrix : \", confusion_matrix(Y_test, pred_test))\n",
        "\n",
        "## Crosstab\n",
        "pd.crosstab(Y_train,pd.Series(pred_train),rownames=['ACTUAL'],colnames=['PRED'])\n",
        "\n",
        "## cross validation accuracy\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "\n",
        "## R cross validation accuracy\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "\n",
        "# ROC AUC plot\n",
        "#baseline model\n",
        "baseline_roc_auc = roc_auc_score(Y_test, model.predict(X_test))\n",
        "fprB, tprB, thresholdsB = roc_curve(Y_test, model.predict_proba(X_test)[:,1])\n",
        "## #model 1\n",
        "## model1_roc_auc = roc_auc_score(y_test, model1.predict(X_test))\n",
        "## fpr1, tpr1, thresholds1 = roc_curve(y_test, model1.predict_proba(X_test)[:,1])\n",
        "## #new tuned model \n",
        "## new_roc_auc = roc_auc_score(y_test, new.predict(X_test))\n",
        "## fprnew, tprnew, thresholds_new = roc_curve(y_test, new.predict_proba(X_test)[:,1])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fprB, tprB, label='GBM Baseline (area = %0.2f)' % baseline_roc_auc)\n",
        "## plt.plot(fpr1, tpr1, label='GBM Model 1 (area = %0.2f)' % model1_roc_auc)\n",
        "## plt.plot(fprnew, tprnew, label='GBM Final Model (area = %0.2f)' % new_roc_auc)\n",
        "\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95diUO1X6fLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##4) Prediction 4 \n",
        "\n",
        "#4.1) Ensembling \n",
        "\n",
        "#For the fourth prediction we'll use an ensemble model."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab2H-Wgi6fJM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##4.2) Stacking ensemble"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "macE8Avh6fG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Voting ensemble\n",
        "model1 = LogisticRegression(random_state=1)\n",
        "model2 = DecisionTreeClassifier(random_state=1)\n",
        "model3 = KNeighborsClassifier()\n",
        "model = VotingClassifier(estimators=[('lr', model1), ('dt', model2), ('knn', model3)], voting='hard')\n",
        "model.fit(X_train,Y_train)\n",
        "model.score(X_test,Y_test) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYxpwj3k6fEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Averaging ensemble\n",
        "model1 = DecisionTreeClassifier()\n",
        "model2 = KNeighborsClassifier()\n",
        "model3= LogisticRegression()\n",
        "\n",
        "model1.fit(X_train,Y_train)\n",
        "model2.fit(X_train,Y_train)\n",
        "model3.fit(X_train,Y_train)\n",
        "\n",
        "pred1=model1.predict_proba(X_test)\n",
        "pred2=model2.predict_proba(X_test)\n",
        "pred3=model3.predict_proba(X_test)\n",
        "\n",
        "finalpred=(pred1+pred2+pred3)/3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xikIDQWZ6fCv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## weighted Averaging ensemble\n",
        "model1 = DecisionTreeClassifier()\n",
        "model2 = KNeighborsClassifier()\n",
        "model3= LogisticRegression()\n",
        "\n",
        "model1.fit(X_train,Y_train)\n",
        "model2.fit(X_train,Y_train)\n",
        "model3.fit(X_train,Y_train)\n",
        "\n",
        "pred1=model1.predict_proba(X_test)\n",
        "pred2=model2.predict_proba(X_test)\n",
        "pred3=model3.predict_proba(X_test)\n",
        "\n",
        "finalpred=(pred1*0.3+pred2*0.3+pred3*0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6geF4686e7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Stacking model\n",
        "def Stacking(model,train,y,test,n_fold):\n",
        "   folds=StratifiedKFold(n_splits=n_fold,random_state=1)\n",
        "   test_pred=np.empty((test.shape[0],1),float)\n",
        "   train_pred=np.empty((0,1),float)\n",
        "   for train_indices,val_indices in folds.split(train,y.values):\n",
        "      x_train,x_val=train.iloc[train_indices],train.iloc[val_indices]\n",
        "      y_train,y_val=y.iloc[train_indices],y.iloc[val_indices]\n",
        "\n",
        "      model.fit(X=x_train,y=y_train)\n",
        "      train_pred=np.append(train_pred,model.predict(x_val))\n",
        "      test_pred=np.append(test_pred,model.predict(test))\n",
        "      return test_pred.reshape(-1,1),train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkYuYMWb6e5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = DecisionTreeClassifier(random_state=1)\n",
        "\n",
        "test_pred1 ,train_pred1=Stacking(model=model1,n_fold=10, train=X_train,test=X_test,y=Y_train)\n",
        "\n",
        "train_pred1=pd.DataFrame(train_pred1)\n",
        "test_pred1=pd.DataFrame(test_pred1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOxixjt86e32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = KNeighborsClassifier()\n",
        "\n",
        "test_pred2 ,train_pred2=Stacking(model=model2,n_fold=10,train=X_train,test=X_test,y=Y_train)\n",
        "\n",
        "train_pred2=pd.DataFrame(train_pred2)\n",
        "test_pred2=pd.DataFrame(test_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziG9Pab06e1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([train_pred1, train_pred2], axis=1)\n",
        "df_test = pd.concat([test_pred1, test_pred2], axis=1)\n",
        "\n",
        "model = LogisticRegression(random_state=1)\n",
        "model.fit(df,Y_train)\n",
        "model.score(df_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1vfCM1kxx0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##5) Prediction 5\n",
        "\n",
        "#5.1) EDA In-depth analysis\n",
        "\n",
        "#For the fifth prediction we'll first do an in-depth EDA and then make predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_-qcOEa1hxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "##6) Prediction 6 - Lean XGB prediction\n",
        "\n",
        "#6.1) Lean XGB prediction\n",
        "\n",
        "# For the sixth prediction we'll do a lean prediction with the often best performing\n",
        "# algorithm XG Boost."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL4B_qC-7BUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# XGB classifier \n",
        "model = XGBClassifier(\n",
        "        learning_rate=0.1, \n",
        "        n_estimators=100,\n",
        "        max_depth=3, \n",
        "        min_samples_split=2, \n",
        "        min_samples_leaf=1, \n",
        "        subsample=1,\n",
        "        max_features='sqrt', \n",
        "        random_state=10)\n",
        "\n",
        "model.fit(X_train,Y_train)\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)\n",
        "\n",
        "accuracy_train = accuracy_score(pred_train,Y_train)\n",
        "accuracy_test = accuracy_score(pred_test,Y_test)\n",
        "\n",
        "# from sklearn import metrics\n",
        "# fpr, tpr, _ = metrics.roc_curve(np.array(Y_train), model.predict_proba(X_train)[:,1])\n",
        "# auc_train = metrics.auc(fpr,tpr)\n",
        "\n",
        "# fpr, tpr, _ = metrics.roc_curve(np.array(Y_test), model.predict_proba(X_test)[:,1])\n",
        "# auc_test = metrics.auc(fpr,tpr)\n",
        "\n",
        " ## Cross validation accuracy\n",
        "cross_val_rfc = cross_val_score(estimator=XGBClassifier(), X=X_train, y=Y_train, cv=2, n_jobs=-1)\n",
        "\n",
        "# R Cross validation accuracy\n",
        "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)\n",
        "# evaluate the model on the dataset\n",
        "n_scores = cross_val_score(model, X_train, Y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eppc2v4F7Bbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "##5.7 Prediction\n",
        "\n",
        "#Print model report:\n",
        "# print(\"\\nModel Report\")\n",
        "# print('AUC:',(auc_test))\n",
        "print(\"Cross Validation Accuracy : \",round(cross_val_rfc.mean() * 100 , 2),\"%\")\n",
        "print(' R Cv Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
        "# print(\"Cross Validation Accuracy: \")\n",
        "# print(classification_report(Y_test, pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMFbhGJe7BQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "######################################################################################################################\n",
        "######################################################################################################################\n",
        "\n",
        "# Optimization 1: \n",
        "\n",
        "# Optimization 2: \n",
        "\n",
        "# Optimization 3: \n",
        "\n",
        "# etc."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}