{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced_programming_5_Sklearn_base.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bPf6ILT7MyH"
      },
      "source": [
        "## Confidentiality\r\n",
        "\r\n",
        "The programmatic cases in this notebook are utilized from different internet resources.\r\n",
        "\r\n",
        "Please do not copy or distribute this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsemtwF_jCEF"
      },
      "source": [
        "## Table of content\r\n",
        "\r\n",
        "Sklearn.base\r\n",
        "\r\n",
        "1. Programmatic case 1 \r\n",
        "2. Programmatic case 2 \r\n",
        "3. Programmatic case 3 \r\n",
        "4. Programmatic case 4 \r\n",
        "5. Programmatic case 5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ0_kjJN7aQ9"
      },
      "source": [
        "## Previous knowledge\r\n",
        "\r\n",
        "Please study the following resources for a deep understanding of this notebook.\r\n",
        "\r\n",
        "1.   https://bit.ly/2KvDctl\r\n",
        "(sklearn.base)\r\n",
        "2.   https://bit.ly/3mINOls \r\n",
        "(Sklearn.base topics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3b57vA-uOoz"
      },
      "source": [
        "### Programmatic case 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NR7pR1kd1iL",
        "outputId": "bb275894-6610-4a2d-cf67-7458add356b5"
      },
      "source": [
        "from sklearn.base import BaseEstimator\r\n",
        "from sklearn.base import TransformerMixin\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "class MyOwnTransformer(BaseEstimator, TransformerMixin):\r\n",
        "     def fit(self, X, y=None):\r\n",
        "         return self\r\n",
        "     def transform(self, X):\r\n",
        "         return X\r\n",
        "\r\n",
        "X, y = load_iris(return_X_y=True)\r\n",
        "pipe = make_pipeline(MyOwnTransformer(),\r\n",
        "                      LogisticRegression(random_state=10,\r\n",
        "                                         solver='lbfgs'))\r\n",
        "pipe.fit(X, y)  \r\n",
        "pipe.predict(X)  "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVqVKwBavDWH"
      },
      "source": [
        "### Programmatic case 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ixsEMjpeEya",
        "outputId": "baddf942-a593-4885-84b9-83619f5e7e27"
      },
      "source": [
        "from sklearn.base import RegressorMixin\r\n",
        "import numpy as np\r\n",
        "from sklearn.datasets import load_diabetes\r\n",
        "\r\n",
        "class MyOwnRegressor(BaseEstimator, RegressorMixin):\r\n",
        "     def fit(self, X, y):\r\n",
        "         return self\r\n",
        "     def predict(self, X):\r\n",
        "         return np.mean(X, axis=1)\r\n",
        "\r\n",
        "X, y = load_diabetes(return_X_y=True)\r\n",
        "pipe = make_pipeline(MyOwnTransformer(), MyOwnRegressor())\r\n",
        "pipe.fit(X, y)  \r\n",
        "pipe.predict(X)  \r\n",
        "pipe.score(X, y)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3.90271854560383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3N01DNKjBHY"
      },
      "source": [
        "### Programmatic case 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ty2oPzSDvpjC",
        "outputId": "c9b4eef7-9a4c-4648-b253-0bc16641d22a"
      },
      "source": [
        "from sklearn.base import ClassifierMixin\r\n",
        "\r\n",
        "class MyOwnClassifier(BaseEstimator, ClassifierMixin):\r\n",
        "     def fit(self, X, y):\r\n",
        "         self.classes_ = np.unique(y)\r\n",
        "         return self\r\n",
        "     def predict(self, X):\r\n",
        "         return np.random.randint(0, self.classes_.size,\r\n",
        "                                  size=X.shape[0])\r\n",
        "     def predict_proba(self, X):\r\n",
        "         pred = np.random.rand(X.shape[0], self.classes_.size)\r\n",
        "         return pred / np.sum(pred, axis=1)[:, np.newaxis]\r\n",
        "\r\n",
        "X, y = load_iris(return_X_y=True)\r\n",
        "pipe = make_pipeline(MyOwnTransformer(), MyOwnClassifier())\r\n",
        "pipe.fit(X, y)  \r\n",
        "\r\n",
        "pipe.predict(X)  \r\n",
        "pipe.predict_proba(X)  \r\n",
        "pipe.score(X, y) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bsyPPU13NdG"
      },
      "source": [
        "### Programmatic case 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-ysfA9U0nKS"
      },
      "source": [
        "print(__doc__)\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.base import BaseEstimator, clone\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "from sklearn.datasets import make_blobs\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.utils.metaestimators import if_delegate_has_method\r\n",
        "\r\n",
        "\r\n",
        "N_SAMPLES = 5000\r\n",
        "RANDOM_STATE = 42\r\n",
        "\r\n",
        "\r\n",
        "class InductiveClusterer(BaseEstimator):\r\n",
        "    def __init__(self, clusterer, classifier):\r\n",
        "        self.clusterer = clusterer\r\n",
        "        self.classifier = classifier\r\n",
        "\r\n",
        "    def fit(self, X, y=None):\r\n",
        "        self.clusterer_ = clone(self.clusterer)\r\n",
        "        self.classifier_ = clone(self.classifier)\r\n",
        "        y = self.clusterer_.fit_predict(X)\r\n",
        "        self.classifier_.fit(X, y)\r\n",
        "        return self\r\n",
        "\r\n",
        "    @if_delegate_has_method(delegate='classifier_')\r\n",
        "    def predict(self, X):\r\n",
        "        return self.classifier_.predict(X)\r\n",
        "\r\n",
        "    @if_delegate_has_method(delegate='classifier_')\r\n",
        "    def decision_function(self, X):\r\n",
        "        return self.classifier_.decision_function(X)\r\n",
        "\r\n",
        "\r\n",
        "def plot_scatter(X,  color, alpha=0.5):\r\n",
        "    return plt.scatter(X[:, 0],\r\n",
        "                       X[:, 1],\r\n",
        "                       c=color,\r\n",
        "                       alpha=alpha,\r\n",
        "                       edgecolor='k')\r\n",
        "\r\n",
        "\r\n",
        "# Generating training data from clustering\r\n",
        "X, y = make_blobs(n_samples=N_SAMPLES,\r\n",
        "                  cluster_std=[1.0, 1.0, 0.5],\r\n",
        "                  centers=[(-5, -5), (0, 0), (5, 5)],\r\n",
        "                  random_state=RANDOM_STATE)\r\n",
        "\r\n",
        "\r\n",
        "# Training a clustering algorithm on the training data and get the cluster labels\r\n",
        "clusterer = AgglomerativeClustering(n_clusters=3)\r\n",
        "cluster_labels = clusterer.fit_predict(X)\r\n",
        "\r\n",
        "plt.figure(figsize=(12, 4))\r\n",
        "\r\n",
        "plt.subplot(131)\r\n",
        "plot_scatter(X, cluster_labels)\r\n",
        "plt.title(\"Ward Linkage\")\r\n",
        "\r\n",
        "\r\n",
        "# Generating new samples and plotting them along with the original dataset\r\n",
        "X_new, y_new = make_blobs(n_samples=10,\r\n",
        "                          centers=[(-7, -1), (-2, 4), (3, 6)],\r\n",
        "                          random_state=RANDOM_STATE)\r\n",
        "\r\n",
        "plt.subplot(132)\r\n",
        "plot_scatter(X, cluster_labels)\r\n",
        "plot_scatter(X_new, 'black', 1)\r\n",
        "plt.title(\"Unknown instances\")\r\n",
        "\r\n",
        "\r\n",
        "# Declaring the inductive learning model that it will be used to\r\n",
        "# predict cluster membership for unknown instances\r\n",
        "classifier = RandomForestClassifier(random_state=RANDOM_STATE)\r\n",
        "inductive_learner = InductiveClusterer(clusterer, classifier).fit(X)\r\n",
        "\r\n",
        "probable_clusters = inductive_learner.predict(X_new)\r\n",
        "\r\n",
        "\r\n",
        "plt.subplot(133)\r\n",
        "plot_scatter(X, cluster_labels)\r\n",
        "plot_scatter(X_new, probable_clusters)\r\n",
        "\r\n",
        "# Plotting decision regions\r\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\r\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\r\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\r\n",
        "                     np.arange(y_min, y_max, 0.1))\r\n",
        "\r\n",
        "Z = inductive_learner.predict(np.c_[xx.ravel(), yy.ravel()])\r\n",
        "Z = Z.reshape(xx.shape)\r\n",
        "\r\n",
        "plt.contourf(xx, yy, Z, alpha=0.4)\r\n",
        "plt.title(\"Classify unknown instances\")\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_E7N4V9AcG"
      },
      "source": [
        "The next piece of code presents an example of sklearn.utils.metaestimators and helps to understand the above piece of code.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prJJp8KeNNbk"
      },
      "source": [
        "from sklearn.utils.metaestimators import if_delegate_has_method\r\n",
        "\r\n",
        "class MetaEst(object):\r\n",
        "     def __init__(self, sub_est):\r\n",
        "         self.sub_est = sub_est\r\n",
        "\r\n",
        "     @if_delegate_has_method(delegate='sub_est')\r\n",
        "     def predict(self, X):\r\n",
        "         return self.sub_est.predict(X)\r\n",
        "\r\n",
        "class HasPredict(object):\r\n",
        "     def predict(self, X):\r\n",
        "         return X.sum(axis=1)\r\n",
        "\r\n",
        "class HasNoPredict(object):\r\n",
        "     pass\r\n",
        "\r\n",
        "hasattr(MetaEst(HasPredict()), 'predict')\r\n",
        "\r\n",
        "hasattr(MetaEst(HasNoPredict()), 'predict')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}